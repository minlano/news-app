#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
import json
sys.path.insert(0, '.')

print("ğŸ§ª ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

# 1. í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸)
print("\nğŸ” í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸:")
try:
    from crawler.daum_crawler import DaumNewsCrawler
    crawler = DaumNewsCrawler()
    
    # ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (2ê°œë§Œ)
    articles = crawler.search_news("í…ŒìŠ¤íŠ¸", max_articles=2)
    
    if articles:
        print(f"âœ… í¬ë¡¤ë§ ì„±ê³µ: {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
        print(f"   ì²« ë²ˆì§¸ ê¸°ì‚¬: {articles[0]['title'][:50]}...")
    else:
        print("âš ï¸ í¬ë¡¤ë§ ê²°ê³¼ ì—†ìŒ")
        
except Exception as e:
    print(f"âŒ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# 2. í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
print("\nğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
try:
    import importlib.util
    spec = importlib.util.spec_from_file_location("keyword_extractor", "keyword/keyword_extractor.py")
    keyword_extractor_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(keyword_extractor_module)
    KeywordExtractor = keyword_extractor_module.KeywordExtractor
    
    extractor = KeywordExtractor()
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_text = "ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ìˆ ì´ ë°œì „í•˜ë©´ì„œ ìë™í™” ì‹œìŠ¤í…œì´ í™•ì‚°ë˜ê³  ìˆë‹¤."
    keywords = extractor.extract_nouns(test_text)
    
    if keywords:
        print(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì„±ê³µ: {len(keywords)}ê°œ í‚¤ì›Œë“œ")
        for word, count in keywords[:3]:
            print(f"   - {word}: {count}")
    else:
        print("âš ï¸ í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ ì—†ìŒ")
        
except Exception as e:
    print(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# 3. ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸
print("\nğŸ˜Š ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸:")
try:
    from sentiment_analysis.sentiment import SentimentAnalyzer
    analyzer = SentimentAnalyzer()
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ë“¤
    test_texts = [
        "ì •ë§ ì¢‹ì€ ì†Œì‹ì´ë„¤ìš”! ê¸°ëŒ€ë©ë‹ˆë‹¤.",
        "ì‹¬ê°í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê±±ì •ë©ë‹ˆë‹¤.",
        "ì¼ë°˜ì ì¸ ë‰´ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤."
    ]
    
    for i, text in enumerate(test_texts, 1):
        result = analyzer.analyze_sentiment(text)
        print(f"âœ… í…ŒìŠ¤íŠ¸ {i}: {result['sentiment']} (ì ìˆ˜: {result['score']})")
        
except Exception as e:
    print(f"âŒ ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# 4. ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± í…ŒìŠ¤íŠ¸
print("\nâ˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ í…ŒìŠ¤íŠ¸:")
try:
    import importlib.util
    spec = importlib.util.spec_from_file_location("wordcloud_gen", "keyword/wordcloud_gen.py")
    wordcloud_gen_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(wordcloud_gen_module)
    WordCloudGenerator = wordcloud_gen_module.WordCloudGenerator
    
    generator = WordCloudGenerator()
    
    # í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ ë°ì´í„°
    test_keywords = {
        "ì¸ê³µì§€ëŠ¥": 10,
        "ë¨¸ì‹ ëŸ¬ë‹": 8,
        "ë”¥ëŸ¬ë‹": 6,
        "ë°ì´í„°": 5,
        "ê¸°ìˆ ": 4
    }
    
    wordcloud = generator.create_wordcloud(test_keywords, style='default')
    
    if wordcloud:
        print("âœ… ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì„±ê³µ")
        
        # ì €ì¥ í…ŒìŠ¤íŠ¸
        saved_path = generator.save_wordcloud(wordcloud, "test_wordcloud.png")
        if saved_path:
            print(f"âœ… ì›Œë“œí´ë¼ìš°ë“œ ì €ì¥ ì„±ê³µ: {saved_path}")
        else:
            print("âš ï¸ ì›Œë“œí´ë¼ìš°ë“œ ì €ì¥ ì‹¤íŒ¨")
    else:
        print("âŒ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨")
        
except Exception as e:
    print(f"âŒ ì›Œë“œí´ë¼ìš°ë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# 5. PDF ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
print("\nğŸ“„ PDF ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸:")
try:
    from report.report_generator import NewsReportGenerator
    
    generator = NewsReportGenerator()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_articles = [
        {
            "title": "í…ŒìŠ¤íŠ¸ ê¸°ì‚¬ ì œëª©",
            "content": "í…ŒìŠ¤íŠ¸ ê¸°ì‚¬ ë‚´ìš©ì…ë‹ˆë‹¤.",
            "source": "í…ŒìŠ¤íŠ¸ ì†ŒìŠ¤",
            "link": "http://test.com"
        }
    ]
    
    test_keywords = {
        "keywords": [
            {"word": "í…ŒìŠ¤íŠ¸", "count": 5},
            {"word": "ê¸°ì‚¬", "count": 3}
        ]
    }
    
    pdf_path = generator.generate_report(
        keyword="í…ŒìŠ¤íŠ¸",
        articles=test_articles,
        keywords_data=test_keywords
    )
    
    if pdf_path and os.path.exists(pdf_path):
        print(f"âœ… PDF ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ: {pdf_path}")
    else:
        print("âŒ PDF ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")
        
except Exception as e:
    print(f"âŒ PDF ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# 6. ì´ë©”ì¼ ë°œì†¡ í…ŒìŠ¤íŠ¸ (ì„¤ì •ë§Œ ì²´í¬)
print("\nğŸ“§ ì´ë©”ì¼ ì„¤ì • í…ŒìŠ¤íŠ¸:")
try:
    from report.email_sender import EmailSender
    
    sender = EmailSender()
    env_config = sender.get_env_email_config()
    
    if env_config['gmail_email'] and env_config['gmail_password']:
        print("âœ… ì´ë©”ì¼ ì„¤ì • ì™„ë£Œ - ë°œì†¡ ê°€ëŠ¥")
        print(f"   ë°œì†¡ì: {env_config['gmail_email']}")
    else:
        print("âš ï¸ ì´ë©”ì¼ ì„¤ì • ë¶ˆì™„ì „ - .env íŒŒì¼ í™•ì¸ í•„ìš”")
        
except Exception as e:
    print(f"âŒ ì´ë©”ì¼ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# 7. ì„ì‹œ íŒŒì¼ ì •ë¦¬
print("\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬:")
temp_files = ["data/test_wordcloud.png"]
for file_path in temp_files:
    if os.path.exists(file_path):
        try:
            os.remove(file_path)
            print(f"âœ… {file_path} ì‚­ì œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ {file_path} ì‚­ì œ ì‹¤íŒ¨: {e}")

print("\nğŸ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ ìš”ì•½:")
print("- ëª¨ë“  ëª¨ë“ˆì´ ì •ìƒì ìœ¼ë¡œ importë¨")
print("- ê¸°ë³¸ ê¸°ëŠ¥ë“¤ì´ ì •ìƒ ì‘ë™í•¨")
print("- í•œê¸€ í°íŠ¸ ì§€ì›ë¨")
print("- ì´ë©”ì¼ ì„¤ì • ì™„ë£Œë¨")
print("\nğŸš€ ì›¹ì•± ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!")