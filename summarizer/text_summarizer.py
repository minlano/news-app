#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í…ìŠ¤íŠ¸ ìš”ì•½ê¸°
sumy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ TextRank ê¸°ë°˜ ìš”ì•½
"""

from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer
from sumy.summarizers.lex_rank import LexRankSummarizer
import re

class TextSummarizer:
    def __init__(self, language='korean'):
        self.language = language
        self.textrank_summarizer = TextRankSummarizer()
        self.lexrank_summarizer = LexRankSummarizer()
    
    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if not text:
            return ""
        
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        text = re.sub(r'\[.*?\]', '', text)  # [ê¸°ìëª…] ë“± ì œê±°
        text = re.sub(r'\(.*?\)', '', text)  # (ê´„í˜¸) ë‚´ìš© ì œê±°
        
        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', ' ', text)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        return text
    
    def summarize_textrank(self, text, sentence_count=3):
        """TextRank ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìš”ì•½"""
        try:
            cleaned_text = self.clean_text(text)
            
            if len(cleaned_text) < 100:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜
                return cleaned_text
            
            # ë¬¸ì¥ì´ ë„ˆë¬´ ì ìœ¼ë©´ sentence_count ì¡°ì •
            sentences = cleaned_text.split('.')
            if len(sentences) <= sentence_count:
                return cleaned_text
            
            parser = PlaintextParser.from_string(cleaned_text, Tokenizer(self.language))
            summary = self.textrank_summarizer(parser.document, sentence_count)
            
            summary_text = ' '.join([str(sentence) for sentence in summary])
            return summary_text
            
        except Exception as e:
            print(f"âŒ TextRank ìš”ì•½ ì˜¤ë¥˜: {e}")
            return self.clean_text(text)[:200] + "..."  # ì‹¤íŒ¨ì‹œ ì•ë¶€ë¶„ë§Œ ë°˜í™˜
    
    def summarize_lexrank(self, text, sentence_count=3):
        """LexRank ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìš”ì•½"""
        try:
            cleaned_text = self.clean_text(text)
            
            if len(cleaned_text) < 100:
                return cleaned_text
            
            sentences = cleaned_text.split('.')
            if len(sentences) <= sentence_count:
                return cleaned_text
            
            parser = PlaintextParser.from_string(cleaned_text, Tokenizer(self.language))
            summary = self.lexrank_summarizer(parser.document, sentence_count)
            
            summary_text = ' '.join([str(sentence) for sentence in summary])
            return summary_text
            
        except Exception as e:
            print(f"âŒ LexRank ìš”ì•½ ì˜¤ë¥˜: {e}")
            return self.clean_text(text)[:200] + "..."
    
    def summarize_simple(self, text, max_length=200):
        """ê°„ë‹¨í•œ ìš”ì•½ (ì•ë¶€ë¶„ ì¶”ì¶œ)"""
        cleaned_text = self.clean_text(text)
        
        if len(cleaned_text) <= max_length:
            return cleaned_text
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        sentences = cleaned_text.split('.')
        summary = ""
        
        for sentence in sentences:
            if len(summary + sentence) <= max_length:
                summary += sentence + "."
            else:
                break
        
        return summary.strip()
    
    def summarize_articles(self, articles, method='textrank', sentence_count=3):
        """ì—¬ëŸ¬ ê¸°ì‚¬ë¥¼ ìš”ì•½"""
        print(f"ğŸ“ {method} ë°©ì‹ìœ¼ë¡œ ê¸°ì‚¬ ìš”ì•½ ì¤‘...")
        
        summarized_articles = []
        
        for i, article in enumerate(articles, 1):
            print(f"ğŸ“„ {i}/{len(articles)}: {article['title'][:30]}... ìš”ì•½ ì¤‘")
            
            # ë³¸ë¬¸ì´ ìˆìœ¼ë©´ ë³¸ë¬¸ì„, ì—†ìœ¼ë©´ ìš”ì•½ì„ ì‚¬ìš©
            text_to_summarize = article.get('content', '') or article.get('summary', '')
            
            if method == 'textrank':
                summary = self.summarize_textrank(text_to_summarize, sentence_count)
            elif method == 'lexrank':
                summary = self.summarize_lexrank(text_to_summarize, sentence_count)
            else:
                summary = self.summarize_simple(text_to_summarize)
            
            # ê¸°ì‚¬ ì •ë³´ì— ìš”ì•½ ì¶”ê°€
            article_copy = article.copy()
            article_copy['ai_summary'] = summary
            summarized_articles.append(article_copy)
        
        print(f"âœ… {len(summarized_articles)}ê°œ ê¸°ì‚¬ ìš”ì•½ ì™„ë£Œ!")
        return summarized_articles

if __name__ == "__main__":
    # ê°œë°œìš© í…ŒìŠ¤íŠ¸ ì½”ë“œ
    pass